# ENV = "InvertedPendulumAdv-v1"
# MAX_ADVERSARY_STRENGTH = 5
# SEED = 0
# DISCOUNT = 0.99
# POLICY_NOISE = 0.2
# EXPLORE_NOISE = 0.2
# NOISE_CLIP = 0.4
# POLICY_CLIP = 0.2
# POLICY_FREQUENCY = 2
# TIMESTEPS_PER_BATCH = 128
# N_UPDATES_PER_ITERATION = 10
# REWARD_THRESH = 1000
# HIDDEN_LAYER_DIM = 256
# LR = 3e-4
# N_TRAINING = 3000
# EVAL_EPISODES = 10
# RARL_LOOPS = 75
# MAX_STEPS_PER_EPISODE = 1000
# NUM_EXPERIMENTS = 5
# SAVE_DIR = './pendulum_data/'

# ENV = 'HalfCheetahTorsoAdv-v1'
# MAX_ADVERSARY_STRENGTH = 3
# SEED = 0
# DISCOUNT = 0.99
# POLICY_NOISE = 0.2
# EXPLORE_NOISE = 0.2
# NOISE_CLIP = 0.4
# POLICY_CLIP = 0.2
# POLICY_FREQUENCY = 2
# TIMESTEPS_PER_BATCH = 2048
# N_UPDATES_PER_ITERATION = 10
# REWARD_THRESH = 6000
# HIDDEN_LAYER_DIM = 256
# LR = 3e-4
# N_TRAINING = 100000
# EVAL_EPISODES = 10
# RARL_LOOPS = 100
# MAX_STEPS_PER_EPISODE = 500
# NUM_EXPERIMENTS = 5
# SAVE_DIR = './halfcheetah_data_torso/'

ENV = 'HopperHeelAdv-v1'

MAX_ADVERSARY_STRENGTH = 3
SEED = 0
BATCH_SIZE = 512
DISCOUNT = 0.99
POLICY_NOISE = 0.2
EXPLORE_NOISE = 0.2
NOISE_CLIP = 0.4
POLICY_CLIP = 0.2
POLICY_FREQUENCY = 2
TIMESTEPS_PER_BATCH = 256
N_UPDATES_PER_ITERATION = 10
REWARD_THRESH = 3800.0
HIDDEN_LAYER_DIM = 256
LR = 3e-4
N_TRAINING = 6000
EVAL_EPISODES = 10
RARL_LOOPS = 100
MAX_STEPS_PER_EPISODE = 1000
NUM_EXPERIMENTS = 5
SAVE_DIR = './hopper_data/'